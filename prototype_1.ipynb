{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class soc_nn:\n",
    "    def __init__(self, data, layer_size, no_nodes, no_epochs, batch, opt):\n",
    "        self.x_train = data[0]\n",
    "        self.y_train = data[1]\n",
    "        self.x_test = data[2]\n",
    "        self.y_test = data[3]\n",
    "        self.batch_size = batch\n",
    "        self.number_of_nodes = no_nodes\n",
    "        self.layer_size = layer_size\n",
    "        self.optimizer = opt\n",
    "        self.number_of_epochs = no_epochs\n",
    "\n",
    "    def run(self):\n",
    "        # Building the model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(len(self.x_train[0]), input_dim=len(self.x_train[0])))\n",
    "        if self.layer_size >= 1:\n",
    "            model.add(Dense(self.number_of_nodes[0], activation='relu'))\n",
    "        if self.layer_size >= 2:\n",
    "            model.add(Dense(self.number_of_nodes[1], activation='relu'))\n",
    "        if self.layer_size >= 3:\n",
    "            model.add(Dense(self.number_of_nodes[2], activation='relu'))\n",
    "\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compiling the model\n",
    "        model.compile(loss='mean_absolute_error', optimizer=self.optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # [['accuracy'], ['accuracy', 'mse']]\n",
    "        model.summary()\n",
    "\n",
    "        # Training the model\n",
    "        model.fit(self.x_train, self.y_train, epochs=self.number_of_epochs, validation_data=(self.x_test, self.y_test),\n",
    "                  batch_size=self.batch_size, verbose=0)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "def scale_between_0_and_1(df, label):\n",
    "    if min(df[label]) >= 0:\n",
    "        return df[label] / max(df[label])\n",
    "    else:\n",
    "        return (df[label] + abs(min(df[label]))) / (max(df[label]) + abs(min(df[label])))\n",
    "\n",
    "\n",
    "def scale_between_minus1_and_1(df, label):\n",
    "    if abs(min(df[label])) <= max(df[label]):\n",
    "        df[label] /= max(df[label])\n",
    "    else:\n",
    "        df[label] /= abs(min(df[label]))\n",
    "    return df[label]\n",
    "\n",
    "\n",
    "def normalize_data(df):\n",
    "    # creating a list of dataframe columns\n",
    "    columns = list(df)\n",
    "    for i in columns:\n",
    "        if i == 'I_m':\n",
    "            df[i] = scale_between_minus1_and_1(df, i)\n",
    "        elif i == 'mode' or i == 'B_E' or i == 'date':\n",
    "            pass\n",
    "        else:\n",
    "            df[i] = scale_between_0_and_1(df, i)\n",
    "    return df\n",
    "\n",
    "\n",
    "def optimizer():\n",
    "    # Optimizer\n",
    "    adam = optimizers.Adam(lr=0.0001)\n",
    "    adadelta = optimizers.Adadelta(lr=1.0, rho=0.95)\n",
    "    rmsprop = optimizers.RMSprop(lr=0.001, rho=0.9)\n",
    "    return [adam, adadelta, rmsprop]\n",
    "\n",
    "\n",
    "def data_prep(data1, data2):\n",
    "    # Prepare usable input parameters\n",
    "    data1['I_m'] = round(data1['mode'] * data1['B_E'] * data1['I_m'], 3)\n",
    "    data2['I_m'] = round(data2['mode'] * data2['B_E'] * data2['I_m'], 3)\n",
    "    y_d1 = scale_between_0_and_1(data1, 'SoC')\n",
    "    y_d2 = scale_between_0_and_1(data2, 'SoC')\n",
    "    x = []\n",
    "    y = [y_d1, y_d2]\n",
    "    label = []\n",
    "    for data in [data1, data2]:\n",
    "        # sample_id, actual_time, mode, B_E, I_m, U_b, T_1, T_2, T_3, delta_time, runtime, dV, dV2, dV3, C\n",
    "        label.append('sample_id, actual_time, mode, B_E, I_m, U_b, T_1, T_2, T_3, delta_time, runtime, dV, dV2, dV3, C')\n",
    "        x_15p = data.drop(['date', 'SoC'], axis=1)\n",
    "        x_15p = normalize_data(x_15p)\n",
    "\n",
    "        # I_m, U_b, T_2, delta_time, runtime, dV, dV2, dV3, C\n",
    "        label.append('I_m, U_b, T_2, delta_time, runtime, dV, dV2, dV3, C')\n",
    "        x_9p = data.drop(['sample_id', 'date', 'actual_time', 'mode', 'B_E', 'T_1', 'T_3', 'SoC'], axis=1)\n",
    "        x_9p = normalize_data(x_9p)\n",
    "\n",
    "        # I_m, U_b, dV, dV2, dV3, C\n",
    "        label.append('I_m, U_b, dV, dV2, dV3, C')\n",
    "        x_6p = data.drop(['sample_id', 'date', 'actual_time', 'mode', 'B_E',\n",
    "                          'T_1', 'T_2', 'T_3', 'delta_time', 'runtime', 'SoC'], axis=1)\n",
    "        x_6p = normalize_data(x_6p)\n",
    "\n",
    "        # I_m, U_b, delta_time, runtime, dV\n",
    "        label.append('I_m, U_b, delta_time, runtime, dV')\n",
    "        x_5p_1 = data.drop(['sample_id', 'date', 'actual_time', 'mode', 'B_E', 'T_1', 'T_2', 'T_3', 'dV2', 'dV3', 'C',\n",
    "                            'SoC'], axis=1)\n",
    "        x_5p_1 = normalize_data(x_5p_1)\n",
    "\n",
    "        # I_m, U_b, dV, dV2, dV3\n",
    "        label.append('I_m, U_b, dV, dV2, dV3')\n",
    "        x_5p_2 = data.drop(['sample_id', 'date', 'actual_time', 'mode', 'B_E',\n",
    "                            'T_1', 'T_2', 'T_3', 'delta_time', 'runtime', 'C', 'SoC'], axis=1)\n",
    "        x_5p_2 = normalize_data(x_5p_2)\n",
    "\n",
    "        # I_m, U_b, delta_time\n",
    "        label.append('I_m, U_b, delta_time')\n",
    "        x_3p = data.drop(['sample_id', 'runtime', 'dV', 'date', 'actual_time', 'mode', 'B_E', 'T_1', 'T_2', 'T_3',\n",
    "                          'dV2', 'dV3', 'C', 'SoC'], axis=1)\n",
    "        x_3p = normalize_data(x_3p)\n",
    "\n",
    "        # I_m, U_b, dV, dV2, dV3, C divided into 3 column groups based on charging mode of the battery\n",
    "        # x_load has 18 parameters\n",
    "        # Divide measurements based on charging load profile\n",
    "        label.append('I_m(ch,idl,dsch), U_b(ch,idl,dsch), dV(ch,idl,dsch), dV2(ch,idl,dsch), dV3(ch,idl,dsch), C(ch,idl,dsch)')\n",
    "        x_load = pd.DataFrame()\n",
    "\n",
    "        x_load['ch1'] = x_6p['U_b']\n",
    "        x_load['ch2'] = x_6p['dV']\n",
    "        x_load['ch3'] = x_6p['dV2']\n",
    "        x_load['ch4'] = x_6p['dV3']\n",
    "        x_load['ch5'] = x_6p['C']\n",
    "        x_load['ch6'] = x_6p['I_m']\n",
    "\n",
    "        x_load['idle1'] = x_6p['U_b']\n",
    "        x_load['idle2'] = x_6p['dV']\n",
    "        x_load['idle3'] = x_6p['dV2']\n",
    "        x_load['idle4'] = x_6p['dV3']\n",
    "        x_load['idle5'] = x_6p['C']\n",
    "        x_load['idle6'] = x_6p['I_m']\n",
    "\n",
    "        x_load['dsch1'] = x_6p['U_b']\n",
    "        x_load['dsch2'] = x_6p['dV']\n",
    "        x_load['dsch3'] = x_6p['dV2']\n",
    "        x_load['dsch4'] = x_6p['dV3']\n",
    "        x_load['dsch5'] = x_6p['C']\n",
    "        x_load['dsch6'] = x_6p['I_m']\n",
    "\n",
    "        # Clear-up\n",
    "        # 1st third of the inputs to represent charging 'ch'\n",
    "        # 2nd third of the inputs to represent Standby or Bypass 'idle'\n",
    "        # 3rd third of the inputs to represent discharging 'dsch'\n",
    "        x_load['ch1'].values[x_6p['I_m'] <= 0] = 0\n",
    "        x_load['ch2'].values[x_6p['I_m'] <= 0] = 0\n",
    "        x_load['ch3'].values[x_6p['I_m'] <= 0] = 0\n",
    "        x_load['ch4'].values[x_6p['I_m'] <= 0] = 0\n",
    "        x_load['ch5'].values[x_6p['I_m'] <= 0] = 0\n",
    "        x_load['ch6'].values[x_6p['I_m'] <= 0] = 0\n",
    "        x_load['idle1'].values[x_6p['I_m'] != 0] = 0\n",
    "        x_load['idle2'].values[x_6p['I_m'] != 0] = 0\n",
    "        x_load['idle3'].values[x_6p['I_m'] != 0] = 0\n",
    "        x_load['idle4'].values[x_6p['I_m'] != 0] = 0\n",
    "        x_load['idle5'].values[x_6p['I_m'] != 0] = 0\n",
    "        x_load['idle6'].values[x_6p['I_m'] != 0] = 0\n",
    "        x_load['dsch1'].values[x_6p['I_m'] >= 0] = 0\n",
    "        x_load['dsch2'].values[x_6p['I_m'] >= 0] = 0\n",
    "        x_load['dsch3'].values[x_6p['I_m'] >= 0] = 0\n",
    "        x_load['dsch4'].values[x_6p['I_m'] >= 0] = 0\n",
    "        x_load['dsch5'].values[x_6p['I_m'] >= 0] = 0\n",
    "        x_load['dsch6'].values[x_6p['I_m'] >= 0] = 0\n",
    "\n",
    "        # I_m, U_b, dV, dV2, dV3 divided into 3 column groups based on charging mode of the battery\n",
    "        # x_load_2 has 15 parameters\n",
    "        label.append('I_m(ch,idl,dsch), U_b(ch,idl,dsch), dV(ch,idl,dsch), dV2(ch,idl,dsch), dV3(ch,idl,dsch)')\n",
    "        x_load_2 = x_load.drop(['ch5', 'idle5', 'dsch5'], axis=1)\n",
    "\n",
    "        x.append([x_15p, x_9p, x_5p_1, x_5p_2, x_3p, x_6p, x_load, x_load_2])\n",
    "\n",
    "    data_sets = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x[i])):\n",
    "            x_train, y_train = x[i][j].to_numpy(), y[i].to_numpy()\n",
    "            x_test, y_test = x[1 - i][j].to_numpy(), y[1 - i].to_numpy()\n",
    "            data_sets.append([x_train, y_train, x_test, y_test])\n",
    "\n",
    "    return data_sets, label\n",
    "\n",
    "\n",
    "def plot_run(error, reference, prediction, label):\n",
    "    plt.subplots(figsize=(10, 12))\n",
    "    #\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.title('x = [' + label + ']')\n",
    "    plt.plot(reference, label='Reference SoC')\n",
    "    plt.plot(prediction, label='Prediction SoC')\n",
    "    plt.xlabel('sample_id')\n",
    "    plt.ylabel('SoC')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.title('Error function')\n",
    "    plt.plot(error, label='Error in SoC prediction')\n",
    "    plt.xlabel('sample_id')\n",
    "    plt.ylabel('Error = |y_ref - y_pred|')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(1-error, label='Accuracy of ' + label)\n",
    "    plt.xlabel('sample_id')\n",
    "    plt.ylabel('Accuracy = 1 - |y_ref - y_pred|')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plot/' + label + '.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_performance(error, accuracy):\n",
    "    plt.subplots(figsize=(10, 8))\n",
    "    #\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.title('Error function')\n",
    "    plt.plot(error, label='Error in SoC prediction')\n",
    "    plt.xlabel('neuralnet_id')\n",
    "    plt.ylabel('Error = |y_ref - y_pred|')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.title('Accuracy')\n",
    "    plt.plot(accuracy, label='Accuracy of prediction')\n",
    "    plt.xlabel('neuralnet_id')\n",
    "    plt.ylabel('Accuracy = 1 - |y_ref - y_pred|')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plot/performance.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_1 = pd.read_csv('data/Augmented_data/battery_data_1_dV-C-roundV.csv')\n",
    "print(\"battery_data_1 has {} data points with {} variables each.\"\n",
    "      .format(*data_1.shape))\n",
    "data_2 = pd.read_csv('data/Augmented_data/battery_data_2_dV-C-roundV.csv')\n",
    "print(\"battery_data_2 has {} data points with {} variables each.\"\n",
    "      .format(*data_2.shape))\n",
    "\n",
    "\n",
    "data_sets, labels = data_prep(data_1, data_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizers = optimizer()\n",
    "hidden_layer_size = [1, 2, 3]\n",
    "number_of_nodes = [18, 120, 64]\n",
    "batch_sizes = [1000, 500, 200, 100, 50]\n",
    "number_of_epochs = [50, 150, 300]\n",
    "\n",
    "errors = []\n",
    "accuracies = []\n",
    "cnt = 1\n",
    "for i in range(len(data_sets)):\n",
    "    for ls in range(len(hidden_layer_size)):\n",
    "        for nn in range(len(number_of_nodes)):\n",
    "            for ne in range(len(number_of_epochs)):\n",
    "                for bs in range(len(batch_sizes)):\n",
    "                    for o in range(len(optimizers)):\n",
    "                        neural_net = soc_nn(data_sets[i],\n",
    "                                            hidden_layer_size[ls],\n",
    "                                            number_of_nodes[nn],\n",
    "                                            number_of_epochs[ne],\n",
    "                                            batch_sizes[bs],\n",
    "                                            optimizers[o])\n",
    "\n",
    "                        model = neural_net.run()\n",
    "\n",
    "                        x_test = data_sets[i][2]\n",
    "                        y_test = data_sets[i][3]\n",
    "\n",
    "                        label = labels[i] + '\\n' + 'ls: {} nn: {} ne: {} bs: {} o: {}'.format(hidden_layer_size[ls],\n",
    "                                                                                              number_of_nodes[nn],\n",
    "                                                                                              number_of_epochs[ne],\n",
    "                                                                                              batch_sizes[bs],\n",
    "                                                                                              o+1)\n",
    "\n",
    "                        label = str(cnt) + '_' + label\n",
    "\n",
    "                        pred = model.predict(x_test, batch_size=batch_sizes[bs], verbose=0)\n",
    "                        prediction = []\n",
    "                        for j in range(len(pred)):\n",
    "                            prediction.append(pred[j][0])\n",
    "\n",
    "                        err = np.subtract(y_test, prediction)\n",
    "                        error = np.absolute(err)\n",
    "                        err_mean = np.mean(error)\n",
    "                        accuracies.append(1 - err_mean)\n",
    "                        errors.append(err_mean)\n",
    "                        print('Error: ', err_mean)\n",
    "                        print('Accuracy: ', 1 - err_mean)\n",
    "                        plot_run(error, y_test, prediction, label)\n",
    "                        cnt += 1\n",
    "\n",
    "np.savetxt(\"error.csv\", errors, delimiter=\",\")\n",
    "np.savetxt(\"accuracy.csv\", accuracies, delimiter=\",\")\n",
    "plot_performance(errors, accuracies)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}